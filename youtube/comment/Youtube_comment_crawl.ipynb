import pandas as pd
import numpy as np
import ast
import pymysql
import requests
from bs4 import BeautifulSoup
from datetime import datetime                                
import time
import datetime as dt
import urllib.request
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
import json
import re     
host = "server"
port = 3306
username = "user"
password = "pw"
db = "db"
conn  = pymysql.connect(host=host, port=port,user=username,passwd=password,db=db)  
cursor = conn.cursor()
conn.set_charset('utf8')
cursor.execute("Select video_id FROM utube_video_info limit 1000")
#item = cursor.fetchall()
row = [item[0] for item in cursor.fetchall()]
row

url = 'https://www.youtube.com/watch?v='
driver = webdriver.Chrome('chromedriver.exe')

url_final = []
id_final = []
comment_final = []

for i in range(len(row)):
    driver.get(url+row[i])
    last_height = driver.execute_script("return document.documentElement.scrollHeight")

    while True:
        driver.execute_script("window.scrollTo(0, document.documentElement.scrollHeight);")
        time.sleep(1.5)

        new_height = driver.execute_script("return document.documentElement.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

    time.sleep(1.5)

    try:
        driver.find_element_by_css_selector("#dismiss-button > a").click()
    except:
        pass
    html_source = driver.page_source
    soup = BeautifulSoup(html_source, 'lxml')
    youtube_user_IDs = soup.select('div#header-author > h3 > #author-text > span') 
    youtube_comments = soup.select('yt-formatted-string#content-text')
    
    for j in range(len(youtube_comments)):
        url_final.append(url+row[i])        
        temp_id = youtube_user_IDs[j].text.strip()
        id_final.append(temp_id)
        temp_comment = youtube_comments[j].text.strip()
        comment_final.append(temp_comment)
    
